{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bef32644",
   "metadata": {},
   "source": [
    "# ðŸ“¦ Imports\n",
    "This section includes necessary Python libraries for data processing, machine learning (PyTorch), visualization, metrics evaluation, and file handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c12d77-5a56-4836-82d3-fc8696badcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "\n",
    "import torch\n",
    "import torch.fft as fft\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "import math\n",
    "import argparse\n",
    "import json\n",
    "\n",
    "import h5py\n",
    "from torch.utils.data import Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2edcec",
   "metadata": {},
   "source": [
    "# ðŸ“š STORMAIDataset Definition\n",
    "Defines a custom PyTorch Dataset class to load and preprocess STORMAI data from HDF5 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c970503c-4d57-45b2-b864-ae2f04ef12cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STORMAIDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.y = None\n",
    "\n",
    "        self.col_ranges = {\n",
    "        'altitude': (0,1000),\n",
    "        'ap_index_nT': (0,400),\n",
    "        'f10.7_index': (63.4,250),\n",
    "        'Lyman_alpha': (0.00588,0.010944),\n",
    "        'Dst_index_nT': (-422,71),\n",
    "        'BX_nT_GSE_GSM': (-40.8,34.8),\n",
    "        'BY_nT_GSE': (-33.2,63.4),\n",
    "        'BZ_nT_GSE': (-53.7,37.5),\n",
    "        'SW_Proton_Density_N_cm3': (0.1,137.2),\n",
    "        'SW_Plasma_Speed_km_s': (233,1189),\n",
    "        'Magnetosonic_Mach_number': (0.6,14.3),\n",
    "        'log_Lyman_alpha2': (4, 8),\n",
    "        'f10.7_index2': (3969, 62500),\n",
    "        'Lyman_alpha_f10.7': (0, 2.75),\n",
    "        'ap_index_nT2': (0, 1.6e5),\n",
    "        'ap_index_nT_f10.7': (0, 1e5),\n",
    "        'log_xrsb_flux': (2.5, 5),\n",
    "        'log_xrsb_flux2': (5,10),\n",
    "        'log_xrsb_flux_Lyman_alpha': (5, 9)\n",
    "        }\n",
    "\n",
    "        self.sw_varlist = ['ap_index_nT', 'f10.7_index', 'Lyman_alpha', 'Dst_index_nT',\n",
    "                'BX_nT_GSE_GSM', 'BY_nT_GSE', 'BZ_nT_GSE', 'SW_Proton_Density_N_cm3',\n",
    "                'SW_Plasma_Speed_km_s', 'Magnetosonic_Mach_number', 'Lyman_alpha2',\n",
    "                'f10.7_index2', 'Lyman_alpha_f10.7', 'ap_index_nT2', 'ap_index_nT_f10.7',\n",
    "                'xrsb_flux', 'xrsb_flux2', 'xrsb_flux_Lyman_alpha']\n",
    "        self.features = ['altitude', 'ap_index_nT', 'f10.7_index', 'Lyman_alpha', 'Dst_index_nT',\n",
    "                'BX_nT_GSE_GSM', 'BY_nT_GSE', 'BZ_nT_GSE', 'SW_Proton_Density_N_cm3',\n",
    "                'SW_Plasma_Speed_km_s', 'Magnetosonic_Mach_number', 'log_Lyman_alpha2',\n",
    "                'f10.7_index2', 'Lyman_alpha_f10.7', 'ap_index_nT2', 'ap_index_nT_f10.7',\n",
    "                'log_xrsb_flux', 'log_xrsb_flux2', 'log_xrsb_flux_Lyman_alpha']\n",
    "\n",
    "    def load_hdf5(self, filelist):\n",
    "        x = []\n",
    "        y = []\n",
    "        alt_array = []\n",
    "\n",
    "        for path in filelist:\n",
    "            with h5py.File(path, 'r') as f:\n",
    "                tmpy = np.array(f['density'])[:,:,3]\n",
    "                tmpx = np.array(f['space_weather'])\n",
    "                tmp_alt_array = np.array(f['density'])[:,0,2]\n",
    "                x.append(tmpx)\n",
    "                y.append(tmpy)\n",
    "                alt_array.append(tmp_alt_array)\n",
    "\n",
    "        x = np.concatenate(x)\n",
    "        y = np.concatenate(y)\n",
    "        alt_array = np.concatenate(alt_array)\n",
    "\n",
    "        # convert space-weather variables to log scale\n",
    "        log_varlist = ['Lyman_alpha2', 'xrsb_flux', 'xrsb_flux2', 'xrsb_flux_Lyman_alpha']\n",
    "        for v in log_varlist:\n",
    "            idx = self.sw_varlist.index(v)\n",
    "            mask = (x[:,:,idx]==0)\n",
    "            x[:,:,idx] = x[:,:,idx]+(mask)*(10**(-self.col_ranges['log_'+v][0]))\n",
    "            x[:,:,idx] = -np.log10(x[:,:,idx])\n",
    "\n",
    "        # Add altitudes form density data to SW data\n",
    "        altitudes = (np.ones((x.shape[1], x.shape[0]))*alt_array).T.reshape(x.shape[0], x.shape[1], 1)\n",
    "        x = np.concatenate((altitudes, x), axis=2)\n",
    "\n",
    "        # scale the features\n",
    "        for idx, v in enumerate(self.features):\n",
    "            x[:,:,idx] = (x[:,:,idx] - self.col_ranges[v][0]) / (self.col_ranges[v][1] - self.col_ranges[v][0])\n",
    "\n",
    "        # convert density values to log scale\n",
    "        y = (y<=0)*1e-15 + (y>0)*y\n",
    "\n",
    "        # permute the last two dimensions of feature tensor\n",
    "        self.x = torch.from_numpy(x).float().permute(0, 2, 1)\n",
    "        self.y = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78fccec9-ecbd-48da-a0dc-d05186de5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STORMAILoader(DataLoader):\n",
    "    def __init__(self, x, y, **kwargs): # Add **kwargs here\n",
    "        super(STORMAILoader, self).__init__(dataset=[(x_i, y_i) for x_i, y_i in zip(x, y)], **kwargs) # Pass **kwargs to super().__init__\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503ca8b6-bd03-4725-99cd-f0d79cd27715",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Positional Encoding for time series patches\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(1)]\n",
    "        return x\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Split time series into patches and project to embedding dimension\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size, in_channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Linear(patch_size * in_channels, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len]\n",
    "        batch_size, channels, seq_len = x.shape\n",
    "\n",
    "        # Pad sequence if needed\n",
    "        if seq_len % self.patch_size != 0:\n",
    "            pad_len = self.patch_size - (seq_len % self.patch_size)\n",
    "            x = torch.cat([x, torch.zeros(batch_size, channels, pad_len, device=x.device)], dim=-1)\n",
    "            seq_len += pad_len\n",
    "\n",
    "        # Split into patches\n",
    "        num_patches = seq_len // self.patch_size\n",
    "        x = x.view(batch_size, channels, num_patches, self.patch_size)\n",
    "        x = x.permute(0, 2, 1, 3)  # [batch_size, num_patches, channels, patch_size]\n",
    "        x = x.reshape(batch_size, num_patches, -1)  # Flatten channels and patch_size\n",
    "\n",
    "        # Project to embedding dimension\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "class AdaptiveSpectralBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Adaptive Spectral Block (ASB) that performs frequency domain processing\n",
    "    with adaptive noise filtering\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, threshold_quantile=0.9):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.threshold_quantile = threshold_quantile\n",
    "\n",
    "        # Learnable global and local filters\n",
    "        self.global_filter = nn.Parameter(torch.randn(embed_dim, dtype=torch.cfloat))\n",
    "        self.local_filter = nn.Parameter(torch.randn(embed_dim, dtype=torch.cfloat))\n",
    "\n",
    "        # Learnable threshold parameter\n",
    "        self.threshold = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def adaptive_high_freq_mask(self, x_fft):\n",
    "        \"\"\"\n",
    "        Create adaptive mask for high frequency components\n",
    "        \"\"\"\n",
    "        # Calculate power spectrum\n",
    "        power = torch.abs(x_fft).pow(2)\n",
    "\n",
    "        # Compute adaptive threshold\n",
    "        threshold = torch.quantile(power, self.threshold_quantile)\n",
    "\n",
    "        # Create mask (1 for frequencies to keep, 0 for those to filter)\n",
    "        mask = (power > threshold * self.threshold).float()\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, embed_dim]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, embed_dim = x.shape\n",
    "\n",
    "        # Apply FFT along the sequence dimension\n",
    "        x_fft = fft.fft(x, dim=1)\n",
    "\n",
    "        # Adaptive filtering\n",
    "        mask = self.adaptive_high_freq_mask(x_fft)\n",
    "        x_filtered = x_fft * mask\n",
    "\n",
    "        # Apply global and local filters\n",
    "        x_global = x_fft * self.global_filter\n",
    "        x_local = x_filtered * self.local_filter\n",
    "\n",
    "        # Combine and inverse FFT\n",
    "        x_combined = x_global + x_local\n",
    "        x_out = fft.ifft(x_combined, dim=1).real\n",
    "\n",
    "        # Layer normalization\n",
    "        x_out = self.norm(x_out)\n",
    "        return x_out\n",
    "\n",
    "class InteractiveConvolutionBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Interactive Convolution Block (ICB) with parallel convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, kernel_sizes=[3, 5]):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(embed_dim, embed_dim, kernel_sizes[0], padding='same')\n",
    "        self.conv2 = nn.Conv1d(embed_dim, embed_dim, kernel_sizes[1], padding='same')\n",
    "        self.conv3 = nn.Conv1d(embed_dim, embed_dim, 1)  # Final mixing convolution\n",
    "        self.activation = nn.GELU()\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, embed_dim]\n",
    "        \"\"\"\n",
    "        # Permute for convolution\n",
    "        x_perm = x.permute(0, 2, 1)  # [batch_size, embed_dim, seq_len]\n",
    "\n",
    "        # First convolution path\n",
    "        conv1_out = self.conv1(x_perm)\n",
    "        conv2_out = self.conv2(x_perm)\n",
    "\n",
    "        # Interactive multiplication\n",
    "        a1 = self.activation(conv1_out) * conv2_out\n",
    "        a2 = self.activation(conv2_out) * conv1_out\n",
    "\n",
    "        # Combine and final convolution\n",
    "        combined = a1 + a2\n",
    "        output = self.conv3(combined)\n",
    "\n",
    "        # Permute back and normalize\n",
    "        output = output.permute(0, 2, 1)\n",
    "        output = self.norm(output + x)  # Residual connection\n",
    "        return output\n",
    "\n",
    "class TSLANetLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single TSLANet layer composed of ASB and ICB\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, kernel_sizes=[3, 5]):\n",
    "        super().__init__()\n",
    "        self.asb = AdaptiveSpectralBlock(embed_dim)\n",
    "        self.icb = InteractiveConvolutionBlock(embed_dim, kernel_sizes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.asb(x)\n",
    "        x = self.icb(x)\n",
    "        return x\n",
    "\n",
    "class TSLANet(nn.Module):\n",
    "    \"\"\"\n",
    "    Complete TSLANet model\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, patch_size, embed_dim, num_layers,\n",
    "                 num_classes=None, forecast_horizon=None, kernel_sizes=[3, 5]):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Patch embedding\n",
    "        self.patch_embed = PatchEmbedding(patch_size, in_channels, embed_dim)\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim)\n",
    "\n",
    "        # TSLANet layers\n",
    "        self.layers = nn.ModuleList([\n",
    "            TSLANetLayer(embed_dim, kernel_sizes) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Output heads\n",
    "        self.num_classes = num_classes\n",
    "        self.forecast_horizon = forecast_horizon\n",
    "\n",
    "        if num_classes is not None:\n",
    "            self.classifier = nn.Linear(embed_dim, num_classes)\n",
    "        if forecast_horizon is not None:\n",
    "            self.forecaster = nn.Linear(embed_dim, forecast_horizon)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len]\n",
    "\n",
    "        # Patch embedding\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # Positional encoding\n",
    "        x = self.pos_encoder(x)\n",
    "\n",
    "        # TSLANet layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "\n",
    "        # Global average pooling\n",
    "        x = x.mean(dim=1)  # [batch_size, embed_dim]\n",
    "\n",
    "        # Output heads\n",
    "        outputs = {}\n",
    "        if self.num_classes is not None:\n",
    "            outputs['classification'] = self.classifier(x)\n",
    "        if self.forecast_horizon is not None:\n",
    "            outputs['forecasting'] = self.forecaster(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1569f090-d48f-4da1-abcf-7483ae81cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = -np.log(1e-5)/431\n",
    "propagation_weights = np.array([np.exp(-rate*i) for i in range(432)])\n",
    "\n",
    "def MAE(true, pred, device='cpu'):\n",
    "    weights_tensor = torch.ones((true.shape[0], 432))#*torch.tensor(propagation_weights)\n",
    "    weights_tensor = weights_tensor.to(device)\n",
    "    loss = torch.sum(torch.abs(true-pred)*weights_tensor, axis=1)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68039e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DerivativeLoss(true, pred, device='cpu'):\n",
    "    weights_tensor = torch.ones((true.shape[0], 432))#*torch.tensor(propagation_weights)\n",
    "    weights_tensor = weights_tensor.to(device)\n",
    "    weights_tensor = weights_tensor.reshape(true.shape[0], 8, 54).mean(dim=2).squeeze(-1)\n",
    "    pred = pred.reshape(true.shape[0], 9, 48).mean(dim=2).squeeze(-1)\n",
    "    true = true.reshape(true.shape[0], 9, 48).mean(dim=2).squeeze(-1)\n",
    "    loss = torch.abs(torch.diff(true, dim=1)-torch.diff(pred, dim=1))*weights_tensor\n",
    "    loss = torch.sum(loss, axis=1)\n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40be75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PropagationLoss(true, pred, device='cpu'):\n",
    "    loss = MAE(true, pred, device)+DerivativeLoss(true, pred, device)\n",
    "    #loss = DrivativeLoss(true, pred, device)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54f2eb06-d3a0-4484-a2c6-7bbee2d01d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_tslanet(model, train_loader, val_loader, task_type='forecasting',\n",
    "                 num_epochs=100, learning_rate=1e-3, weight_decay=1e-4,\n",
    "                 patience=10, device='cuda', pretrain_epochs=0,\n",
    "                 pretrain_loader=None, pretrain_mask_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Train the TSLANet model with optional self-supervised pretraining\n",
    "\n",
    "    Args:\n",
    "        model: TSLANet model instance\n",
    "        train_loader: DataLoader for training data\n",
    "        val_loader: DataLoader for validation data\n",
    "        task_type: 'classification', 'forecasting', or 'both'\n",
    "        num_epochs: Number of training epochs\n",
    "        learning_rate: Initial learning rate\n",
    "        weight_decay: Weight decay for optimizer\n",
    "        patience: Early stopping patience\n",
    "        device: Device to train on ('cuda' or 'cpu')\n",
    "        pretrain_epochs: Number of self-supervised pretraining epochs\n",
    "        pretrain_loader: DataLoader for pretraining (if None, uses train_loader)\n",
    "        pretrain_mask_ratio: Ratio of patches to mask during pretraining\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (trained_model, training_history, best_val_metric)\n",
    "    \"\"\"\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize optimizer and scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min' if task_type != 'classification' else 'max', patience=patience//2)\n",
    "\n",
    "    # Loss functions\n",
    "    if task_type == 'classification' or task_type == 'both':\n",
    "        cls_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "    if task_type == 'forecasting' or task_type == 'both':\n",
    "        #forecast_criterion = nn.MSELoss()\n",
    "        #forecast_criterion = MAE\n",
    "        forecast_criterion = PropagationLoss\n",
    "\n",
    "    pretrain_criterion = nn.MSELoss()  # For self-supervised pretraining\n",
    "\n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'train_metric': [],\n",
    "        'val_metric': [],\n",
    "        'pretrain_loss': []\n",
    "    }\n",
    "\n",
    "    best_val_metric = -np.inf if task_type == 'classification' else np.inf\n",
    "    best_model_state = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    # Self-supervised pretraining phase\n",
    "    if pretrain_epochs > 0:\n",
    "        print(f\"Starting self-supervised pretraining for {pretrain_epochs} epochs...\")\n",
    "        pretrain_loader = pretrain_loader if pretrain_loader is not None else train_loader\n",
    "\n",
    "        for epoch in range(pretrain_epochs):\n",
    "            model.train()\n",
    "            epoch_pretrain_loss = 0.0\n",
    "\n",
    "            for batch in tqdm(pretrain_loader, desc=f\"Pretrain Epoch {epoch+1}/{pretrain_epochs}\"):\n",
    "                x = batch[0].to(device)  # Input time series\n",
    "\n",
    "                # Create masked version for pretraining\n",
    "                batch_size, channels, seq_len = x.shape\n",
    "                num_patches = seq_len // model.patch_size\n",
    "\n",
    "                # Generate random mask (1 = keep, 0 = mask)\n",
    "                mask = torch.ones(batch_size, num_patches, device=device)\n",
    "                num_masked = int(pretrain_mask_ratio * num_patches)\n",
    "\n",
    "                # Mask the input\n",
    "                masked_x = x.clone()\n",
    "                for i in range(batch_size):\n",
    "                    # Reshape to patches\n",
    "                    patches = x[i].unfold(-1, model.patch_size, model.patch_size)  # shape: (in_channels, num_patches, patch_size)\n",
    "\n",
    "                    # Apply mask - Reshape mask to match patches dimension\n",
    "                    masking = mask[i, :patches.shape[1]].view(-1, 1, 1).repeat(1, patches.shape[0], patches.shape[2])\n",
    "                    patches = patches * masking\n",
    "\n",
    "                    # Reshape back\n",
    "                    masked_x[i] = patches.reshape(channels, -1)\n",
    "\n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(masked_x)\n",
    "\n",
    "                # Get reconstruction target (only masked patches)\n",
    "                target = x.clone()\n",
    "                for i in range(batch_size):\n",
    "                    patches = target[i].unfold(-1, model.patch_size, model.patch_size)\n",
    "                    patches = patches * (1 - mask[i].view(-1, 1, 1))  # Only masked patches\n",
    "                    target[i] = patches.reshape(channels, -1)\n",
    "\n",
    "                # Calculate loss and backprop\n",
    "                loss = pretrain_criterion(outputs['forecasting'], target, device=device)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                epoch_pretrain_loss += loss.item()\n",
    "\n",
    "            avg_pretrain_loss = epoch_pretrain_loss / len(pretrain_loader)\n",
    "            history['pretrain_loss'].append(avg_pretrain_loss)\n",
    "            print(f\"Pretrain Epoch {epoch+1} Loss: {avg_pretrain_loss:.4f}\")\n",
    "\n",
    "    # Main training phase\n",
    "    print(f\"Starting main training for {num_epochs} epochs...\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_train_metric = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=f\"Train Epoch {epoch+1}/{num_epochs}\"):\n",
    "            x = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(x)\n",
    "\n",
    "            # Calculate loss based on task type\n",
    "            if task_type == 'classification':\n",
    "                targets = batch[1].to(device)\n",
    "                loss = cls_criterion(outputs['classification'], targets)\n",
    "            elif task_type == 'forecasting':\n",
    "                targets = batch[1].to(device)\n",
    "                loss = forecast_criterion(outputs['forecasting'], targets, device=device)\n",
    "            elif task_type == 'both':\n",
    "                cls_targets = batch[1].to(device)\n",
    "                forecast_targets = batch[2].to(device)\n",
    "                loss = cls_criterion(outputs['classification'], cls_targets) + \\\n",
    "                       forecast_criterion(outputs['forecasting'], forecast_targets, device=device)\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            # Calculate training metric\n",
    "            with torch.no_grad():\n",
    "                if task_type == 'classification':\n",
    "                    preds = torch.argmax(outputs['classification'], dim=1)\n",
    "                    epoch_train_metric += accuracy_score(batch[1].cpu().numpy(), preds.cpu().numpy())\n",
    "                elif task_type == 'forecasting':\n",
    "                    epoch_train_metric += PropagationLoss(batch[1].cpu(), outputs['forecasting'].cpu()).item()\n",
    "\n",
    "                elif task_type == 'both':\n",
    "                    # For 'both' mode, we track classification accuracy as the primary metric\n",
    "                    preds = torch.argmax(outputs['classification'], dim=1)\n",
    "                    epoch_train_metric += accuracy_score(batch[1].cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
    "        avg_train_metric = epoch_train_metric / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_metric'].append(avg_train_metric)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        epoch_val_loss = 0.0\n",
    "        epoch_val_metric = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x = batch[0].to(device)\n",
    "                outputs = model(x)\n",
    "\n",
    "                if task_type == 'classification':\n",
    "                    targets = batch[1].to(device)\n",
    "                    loss = cls_criterion(outputs['classification'], targets)\n",
    "                    preds = torch.argmax(outputs['classification'], dim=1)\n",
    "                    epoch_val_metric += accuracy_score(batch[1].cpu().numpy(), preds.cpu().numpy())\n",
    "                elif task_type == 'forecasting':\n",
    "                    targets = batch[1].to(device)\n",
    "                    loss = forecast_criterion(outputs['forecasting'], targets, device=device)\n",
    "                    epoch_val_metric += PropagationLoss(batch[1].cpu(), outputs['forecasting'].cpu()).item()\n",
    "                elif task_type == 'both':\n",
    "                    cls_targets = batch[1].to(device)\n",
    "                    forecast_targets = batch[2].to(device)\n",
    "                    loss = cls_criterion(outputs['classification'], cls_targets) + \\\n",
    "                           forecast_criterion(outputs['forecasting'], forecast_targets)\n",
    "                    preds = torch.argmax(outputs['classification'], dim=1)\n",
    "                    epoch_val_metric += accuracy_score(batch[1].cpu().numpy(), preds.cpu().numpy())\n",
    "\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = epoch_val_loss / len(val_loader)\n",
    "        avg_val_metric = epoch_val_metric / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_metric'].append(avg_val_metric)\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step(avg_val_metric if task_type == 'classification' else avg_val_loss)\n",
    "\n",
    "        # Print epoch summary\n",
    "        if task_type == 'classification':\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"Train Acc: {avg_train_metric:.4f}, Val Acc: {avg_val_metric:.4f}\")\n",
    "        elif task_type == 'forecasting':\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"Train PMSE: {avg_train_metric:.4f}, Val PMSE: {avg_val_metric:.4f}\")\n",
    "        else:  # both\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "            print(f\"Train Acc: {avg_train_metric:.4f}, Val Acc: {avg_val_metric:.4f}\")\n",
    "\n",
    "        # Check for early stopping and model saving\n",
    "        if ((task_type == 'classification' and avg_val_metric > best_val_metric) or\n",
    "            (task_type != 'classification' and avg_val_metric < best_val_metric)):\n",
    "            best_val_metric = avg_val_metric\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Load best model state\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, history, best_val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ea6f368-4d8b-40d7-babd-1654fb603372",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = STORMAIDataset()\n",
    "data_list = ['../data/transformer_data/dev1.h5',\n",
    "             '../data/transformer_data/dev3.h5',\n",
    "             '../data/transformer_data/dev5.h5',\n",
    "             '../data/transformer_data/dev6.h5',\n",
    "             '../data/transformer_data/dev7.h5',\n",
    "             '../data/transformer_data/dev8.h5',\n",
    "            '../data/transformer_data/dev9.h5',\n",
    "             '../data/transformer_data/data_large_v2.h5']\n",
    "dataset.load_hdf5(data_list)\n",
    "sample_size = len(dataset.y)\n",
    "train_size = int(sample_size*0.9)\n",
    "rnidx = np.random.permutation(sample_size)\n",
    "train_idx = rnidx[:train_size]\n",
    "val_idx = rnidx[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a22f33b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.x = torch.nan_to_num(dataset.x, 0)\n",
    "dataset.y = torch.nan_to_num(dataset.y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248ee593",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.x\n",
    "Y = torch.log(dataset.y)\n",
    "Y = (dataset.y-dataset.y[:,0].reshape(dataset.y.shape[0], 1))/dataset.y[:,0].reshape(dataset.y.shape[0], 1)\n",
    "Y = torch.nan_to_num(Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab719d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = STORMAIDataset()\n",
    "dataset_list = ['../data/transformer_data/train.h5',\n",
    "                '../data/transformer_data/phase1p1.h5',\n",
    "                '../data/transformer_data/phase1p2.h5']\n",
    "dataset_test.load_hdf5(data_list)\n",
    "sample_size = len(dataset_test.y)\n",
    "dataset_test.x = torch.nan_to_num(dataset_test.x, 0)\n",
    "dataset_test.y = torch.nan_to_num(dataset_test.y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8473c4ab-5a9c-414f-bce5-4e094c3cba37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration\n",
    "in_channels = 19  # Univariate time series\n",
    "patch_size = 48\n",
    "embed_dim = 64\n",
    "num_layers = 5\n",
    "num_classes = None  # For classification\n",
    "forecast_horizon = 432  # For forecasting\n",
    "\n",
    "# Create model\n",
    "model = TSLANet(\n",
    "    in_channels=in_channels,\n",
    "    patch_size=patch_size,\n",
    "    embed_dim=embed_dim,\n",
    "    num_layers=num_layers,\n",
    "    num_classes=num_classes,\n",
    "    forecast_horizon=forecast_horizon\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('tslanet_v5.pkl', weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12a112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = STORMAILoader(X[train_idx], Y[train_idx], batch_size=512)\n",
    "val_loader = STORMAILoader(X[val_idx], Y[val_idx], batch_size=512)\n",
    "test_loader = STORMAILoader(dataset_test.x, dataset_test.y, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0833510-54a5-40b1-96a5-f03391e26690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model (classification + forecasting)\n",
    "trained_model, history, best_metric = train_tslanet(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    task_type='forecasting',\n",
    "    num_epochs=100,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    patience=10,\n",
    "    device='cuda:0',\n",
    "    pretrain_epochs=0  # Optional pretraining\n",
    ")\n",
    "\n",
    "print(f\"Training complete. Best validation metric: {best_metric:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc7549-5014-4fd1-ae43-96c0ce703b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.582897862584793e-13\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "n = 0\n",
    "rmse = 0\n",
    "with torch.no_grad():\n",
    "    for ibatch, batch in enumerate(val_loader):\n",
    "        x = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        outputs = model(x)\n",
    "        truth = y.cpu().numpy()\n",
    "        pred = outputs['forecasting'].cpu().numpy()\n",
    "        truth = np.exp(truth)\n",
    "        pred = np.exp(pred)\n",
    "        rmse += np.mean(((truth-pred)**2)*propagation_weights)\n",
    "\n",
    "rmse = np.sqrt(rmse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c3161-da5e-456d-b43d-fe86f53992cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tarray = np.arange(432)\n",
    "with torch.no_grad():\n",
    "    for ibatch, batch in enumerate(test_loader):\n",
    "        x = batch[0].to(device)\n",
    "        y = batch[1].to(device)\n",
    "        outputs = model(x)\n",
    "        truth = y.cpu()\n",
    "        pred = outputs['forecasting'].cpu()\n",
    "        truth = np.exp(truth)\n",
    "        pred = np.exp(pred)\n",
    "        for j in range(pred.shape[0]):\n",
    "            plt.clf()\n",
    "            plt.figure(figsize=(9,3))\n",
    "            plt.plot(tarray, pred[j], label='Preds')\n",
    "            plt.plot(tarray, truth[j], label='True')\n",
    "            plt.xlabel('Timestamp', fontsize=10)\n",
    "            plt.ylabel('Orbit Mean Density (kg/m$^3$)')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "            if j>2: break\n",
    "        if ibatch>10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d244e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'tslanet.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stormai",
   "language": "python",
   "name": "stormai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
